# Self-Aiming-Cannon
The goal of this project was to make an autonomous, self contained turret as cheaply as possible (I spent just $40 on the build). Because it was done so cheaply, I used a raspberry pi zero which could only process one image every few seconds. To get around this speed problem, I sent the raspberry pi's video stream to be processed on a separate computer which then sent commands back to the robot. More complex image analysis can be done at a quick frame rate all completely locally with this method. I first followed a tutorial (https://picamera.readthedocs.io/en/release-1.13/recipes2.html#web-streaming) to stream the raspberry pi's video to a webpage. From my laptop, I could then analyze the stream (using tracker.py and gestureDetector.py) to find my hand coordinates and detect wether or not I had made a fist. I sent this data to a server (using socket communication) which relayed it back to the raspberry pi. The pi positioned the servos, activated the pump once I made a fist, and stopped the pump when the ball left the barrel (using a light sensor). The turret followed my hand in realtime, more than 30 times as fast as image processing just using the pi. 
